{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","mount_file_id":"1wu3n19owBFAtpLWuzt9rY-QV43aIs5EV","authorship_tag":"ABX9TyPuWUbj+wPWbnFcQRf8v/Bk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"id":"Blkz792TNNtF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707237836467,"user_tz":-60,"elapsed":36402,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}},"outputId":"826f32bf-4994-4ca9-fea6-1d6ab7bc9091"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m41.0/53.4 kB\u001b[0m \u001b[31m935.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m937.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]},{"output_type":"stream","name":"stderr","text":["100%|████████████████████████████████████████| 278M/278M [00:02<00:00, 107MiB/s]\n"]}],"source":["#@title CLIP preprocess and Imports\n","!pip -q install ftfy regex tqdm\n","!pip -q install git+https://github.com/openai/CLIP.git\n","import os\n","import numpy as np\n","import h5py\n","import torch\n","import clip\n","import cv2\n","from PIL import Image\n","from IPython.display import Image as ImagePy, display\n","import matplotlib.pyplot as plt\n","import torchvision.transforms as transforms\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","import random\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","clip_model, preprocess = clip.load(\"RN101\")"]},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/Columbia Dataset/Speaker Frames/database.h5\" \"/content/data.h5\""],"metadata":{"id":"vZmd-e-TOoxJ","executionInfo":{"status":"ok","timestamp":1707237768868,"user_tz":-60,"elapsed":284030,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["dataset_path = \"/content/data.h5\""],"metadata":{"id":"-XwZpTPX_Sr3","executionInfo":{"status":"ok","timestamp":1707237768869,"user_tz":-60,"elapsed":12,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import h5py\n","with h5py.File(dataset_path, 'r') as f:\n","  l = f['bell']['labels'][0]\n","  f = f['bell']['frames'][0]\n","  print(f.dtype)\n","  print(l.dtype)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B8vQnNYaJdq8","executionInfo":{"status":"ok","timestamp":1703108149400,"user_tz":-60,"elapsed":447,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}},"outputId":"021e3263-cd7f-46ea-d362-5922d971eb72"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["uint8\n","uint8\n"]}]},{"cell_type":"code","source":["excluded_person = \"bollinger\""],"metadata":{"id":"5iqKtzOG1FXI","executionInfo":{"status":"ok","timestamp":1707237768869,"user_tz":-60,"elapsed":10,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["people_list = [\"bell\",\n","               \"sick\",\n","               \"long\",\n","               #\"bollinger\",\n","               \"lieberman\",\n","               ]"],"metadata":{"id":"QL8W9aYkNTi7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Get Train-Val indices\n","train_val_indices = {}\n","with h5py.File(dataset_path, 'r') as f:\n","    for p in people_list:\n","      person = f[p]\n","      indices = person['frames'].attrs.get(\"data_length\")\n","      train_indices, val_indices = train_test_split(np.arange(indices), test_size=0.2, random_state=42)\n","      train_val_indices[p] = (train_indices, val_indices)"],"metadata":{"id":"-VZkHScrh9e6","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Check Chosen People Data\n","print(\"----------------------- TRAIN DATA ---- VAL DATA --- TOTAL DATA\")\n","with h5py.File(dataset_path, 'r') as f:\n","    tot_train = 0\n","    tot_val = 0\n","    for p in people_list:\n","      person = f[p]\n","      total = person['frames'].attrs.get('data_length')\n","\n","      train_size = len(train_val_indices[p][0])\n","      val_size = len(train_val_indices[p][1])\n","\n","      tot_train += train_size\n","      tot_val += val_size\n","      print(f'Group {p}:      \\t{train_size} \\t\\t{val_size} \\t\\t{total}')\n","\n","    print(f\"TOTAL DATA------------- {tot_train} --------- {tot_val} ---------- {tot_train+tot_val}\")"],"metadata":{"id":"sRNcD6XuNTkl","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705612607083,"user_tz":-60,"elapsed":4,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}},"outputId":"7506b17a-02e6-4f5c-9fb7-95a8bce8cb4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------- TRAIN DATA ---- VAL DATA --- TOTAL DATA\n","Group bell:      \t29937 \t\t7485 \t\t37422\n","Group sick:      \t30820 \t\t7706 \t\t38526\n","Group long:      \t23512 \t\t5879 \t\t29391\n","Group lieberman:      \t13120 \t\t3280 \t\t16400\n","TOTAL DATA------------- 97389 --------- 24350 ---------- 121739\n"]}]},{"cell_type":"code","source":["#@title Get Class Weights\n","\n","class_counts = {}\n","\n","# Open the HDF5 file\n","with h5py.File(dataset_path, 'r') as f:\n","    # Iterate over each group (person) in the file\n","    for p in [string for string in [\"bell\", \"sick\", \"long\", \"bollinger\", \"lieberman\"] if string != excluded_person]:\n","        person = f[p]\n","        labels = []\n","        indices = f[p]['frames'].attrs.get(\"data_length\")\n","        for index in np.arange(indices):\n","          labels.append(person['labels'][index])\n","        # Count occurrences of each class in the labels\n","        for label in labels:\n","            class_counts[label] = class_counts.get(label, 0) + 1\n","\n","# Calculate total number of training samples\n","total_train_samples = sum(class_counts.values())\n","\n","# Compute class weights as the inverse of class frequencies\n","class_weights = {cls: total_train_samples / count for cls, count in class_counts.items()}\n","\n","# Normalize the weights so that they sum up to 1 (optional)\n","total_weight = sum(class_weights.values())\n","class_weights_normalized = {cls: weight / total_weight for cls, weight in class_weights.items()}\n","print(class_weights_normalized)\n","# Convert class weights to a tensor\n","class_weights_tensor = torch.tensor(list(class_weights_normalized.values()), dtype=torch.float)\n","positive_class_weight_tensor = class_weights_tensor[1].clone().detach().cuda()"],"metadata":{"id":"2QtZOkVte6Gx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707237871128,"user_tz":-60,"elapsed":34663,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}},"outputId":"d995d7de-da05-470a-b310-9d1e471d4471","cellView":"form"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 0.41363901461322994, 1: 0.5863609853867701}\n"]}]},{"cell_type":"code","source":["#@title Get TEST Weights\n","class_counts = {}\n","with h5py.File(dataset_path, 'r') as f:\n","  test_labels = f[excluded_person][\"labels\"]\n","  for label in test_labels:\n","    class_counts[label] = class_counts.get(label, 0) + 1\n","\n","# Calculate total number of training samples\n","total_train_samples = sum(class_counts.values())\n","\n","# Compute class weights as the inverse of class frequencies\n","class_weights = {cls: total_train_samples / count for cls, count in class_counts.items()}\n","\n","# Normalize the weights so that they sum up to 1 (optional)\n","total_weight = sum(class_weights.values())\n","class_weights_normalized = {cls: weight / total_weight for cls, weight in class_weights.items()}\n","print(class_weights_normalized)\n","# # Convert class weights to a tensor\n","# class_weights_tensor = torch.tensor(list(class_weights_normalized.values()), dtype=torch.float)\n","# positive_class_weight_tensor = class_weights_tensor[1].clone().detach().cuda()"],"metadata":{"id":"iPNcWPtZuwlC","colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","executionInfo":{"status":"ok","timestamp":1706287408074,"user_tz":-60,"elapsed":322,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}},"outputId":"0037b17b-3ba7-4b7d-c0ad-76b3d97dac1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 0.4305059371916573, 1: 0.5694940628083427}\n"]}]},{"cell_type":"code","source":["#@title Data Loader con miglior shuffle tra Speakers\n","class FineTuneDataGenerator:\n","    def __init__(self, data_directory, batch_size, preprocess_f, indices, mode):\n","        self.data_directory = data_directory\n","        self.batch_size = batch_size\n","        self.preprocess = preprocess_f\n","        self.groups = list(indices.keys())\n","        self.mode = mode  # 'train' or 'validation'\n","        self.indices_dict = indices\n","\n","        self.h5_file = h5py.File(self.data_directory, 'r')\n","        group_data = []\n","        for group in self.groups:\n","              frames_dataset = self.h5_file[group]['frames']\n","              labels_dataset = self.h5_file[group]['labels']\n","\n","              if self.mode == 'train':\n","                group_data.append((frames_dataset, labels_dataset, self.indices_dict[group][0]))\n","              else:\n","                group_data.append((frames_dataset, labels_dataset, self.indices_dict[group][1]))\n","\n","        self.group_data = group_data\n","\n","    def close_file(self):\n","      self.h5_file.close()\n","\n","    def shuffle_replenish_data(self):\n","        self.group_data.clear() # resetta la lista di gruppi USATI\n","\n","        for group in self.groups:\n","              frames_dataset = self.h5_file[group]['frames']\n","              labels_dataset = self.h5_file[group]['labels']\n","\n","              if self.mode == 'train':\n","                shuffled_indices = np.random.permutation(self.indices_dict[group][0])\n","                self.group_data.append((frames_dataset, labels_dataset, shuffled_indices))\n","              else:\n","                shuffled_indices = np.random.permutation(self.indices_dict[group][1])\n","                self.group_data.append((frames_dataset, labels_dataset, shuffled_indices))\n","\n","\n","    def __len__(self):\n","        length = 0\n","        for group in self.group_data:\n","          length += len(group[2])\n","\n","        return length // self.batch_size\n","\n","    def __iter__(self):\n","\n","            batch_frames = []\n","            batch_labels = []\n","\n","            # Calculate the number of data points to take from each group per batch\n","            data_per_group = self.batch_size // len(self.groups)\n","\n","            if self.mode == 'train':\n","              # Interleave data from different groups\n","              while any(len(data[2]) for data in self.group_data):\n","                  for _ in range(data_per_group):\n","                      for i, (frames_dataset, labels_dataset, indices) in enumerate(self.group_data):\n","                          if len(indices):\n","                              index = indices[0]\n","                              self.group_data[i] = (frames_dataset, labels_dataset, indices[1:])  # Update the indices in group_data\n","                              frame = frames_dataset[index]\n","                              label = labels_dataset[index]\n","                              f = Image.fromarray(frame)\n","                              f = f.convert('RGB') if f.mode != 'RGB' else f\n","                              batch_frames.append(self.preprocess(f))\n","                              #batch_frames.append(torch.from_numpy(frame))\n","                              batch_labels.append(label)\n","\n","                              # Check if the batch is complete\n","                              if len(batch_frames) == self.batch_size:\n","                                  # Yield the batch and reset the containers\n","                                  yield torch.stack(batch_frames), torch.tensor(batch_labels)\n","\n","                                  batch_frames = []\n","                                  batch_labels = []\n","\n","              # Yield any remaining data as the last batch\n","              if batch_frames:\n","                  yield torch.stack(batch_frames), torch.tensor(batch_labels)\n","\n","            else: # 'validation', no interleaving between groups\n","              for frames_dataset, labels_dataset, indices in self.group_data:\n","                  for index in indices:\n","                      frame = frames_dataset[index]\n","                      label = labels_dataset[index]\n","                      f = Image.fromarray(frame)\n","                      f = f.convert('RGB') if f.mode != 'RGB' else f\n","                      batch_frames.append(self.preprocess(f))\n","                      batch_labels.append(label)\n","\n","                      if len(batch_frames) == self.batch_size:\n","                          # Yield the batch and reset the containers\n","                          yield torch.stack(batch_frames), torch.tensor(batch_labels)\n","                          batch_frames = []\n","                          batch_labels = []\n","\n","              # Yield any remaining data as the last batch\n","              if batch_frames:\n","                  yield torch.stack(batch_frames), torch.tensor(batch_labels)\n"],"metadata":{"id":"f3iRH8PMNTfx","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Data Loader con Validation set = Test set\n","class FineTuneDataGenerator:\n","    def __init__(self, data_directory, batch_size, preprocess_f, excluded_person, mode):\n","        self.data_directory = data_directory\n","        self.batch_size = batch_size\n","        self.preprocess = preprocess_f\n","        self.groups = [\"bell\", \"sick\", \"long\", \"bollinger\", \"lieberman\"]\n","        self.mode = mode  # 'train' or 'validation'\n","        self.excluded_person = excluded_person\n","        self.indices = {}\n","        self.h5_file = h5py.File(self.data_directory, 'r')\n","        group_data = []\n","\n","        # use all people data, except excluded person, for training\n","        if self.mode == 'train':\n","          for group in [string for string in self.groups if string != excluded_person]:\n","              frames_dataset = self.h5_file[group]['frames']\n","              labels_dataset = self.h5_file[group]['labels']\n","              indices = self.h5_file[group]['frames'].attrs.get(\"data_length\")\n","              self.indices[group] = np.arange(indices)\n","\n","              group_data.append((frames_dataset, labels_dataset, np.arange(indices)))\n","\n","          print('--- Training Data ---')\n","          for k in list(self.indices.keys()): print(f'{k} has {len(self.indices[k])} indices')\n","\n","        else: # use excluded person as valdation set\n","          frames_dataset = self.h5_file[excluded_person]['frames']\n","          labels_dataset = self.h5_file[excluded_person]['labels']\n","          indices = self.h5_file[excluded_person]['frames'].attrs.get(\"data_length\")\n","          group_data.append((frames_dataset, labels_dataset, np.arange(indices)))\n","\n","          print(f'--- Validation Data ---\\n{excluded_person} has {indices} indices')\n","\n","        self.group_data = group_data\n","\n","    def close_file(self):\n","      self.h5_file.close()\n","\n","    # for TRAINING only\n","    def shuffle_replenish_data(self):\n","        self.group_data.clear()\n","        for group in [string for string in self.groups if string != self.excluded_person]:\n","              frames_dataset = self.h5_file[group]['frames']\n","              labels_dataset = self.h5_file[group]['labels']\n","\n","              shuffled_indices = np.random.permutation(self.indices[group])\n","              self.group_data.append((frames_dataset, labels_dataset, shuffled_indices))\n","\n","    def __len__(self):\n","        length = 0\n","        for group in self.group_data:\n","          length += len(group[2])\n","\n","        return length // self.batch_size\n","\n","    def __iter__(self):\n","\n","            batch_frames = []\n","            batch_labels = []\n","\n","            # Calculate the number of data points to take from each group per batch\n","            data_per_group = self.batch_size // len(self.groups)\n","\n","            if self.mode == 'train':\n","              # Interleave data from different groups\n","              while any(len(data[2]) for data in self.group_data):\n","                  for _ in range(data_per_group):\n","                      for i, (frames_dataset, labels_dataset, indices) in enumerate(self.group_data):\n","                          if len(indices):\n","                              index = indices[0]\n","                              self.group_data[i] = (frames_dataset, labels_dataset, indices[1:])  # Update the indices in group_data\n","                              frame = frames_dataset[index]\n","                              label = labels_dataset[index]\n","                              f = Image.fromarray(frame)\n","                              f = f.convert('RGB') if f.mode != 'RGB' else f\n","                              batch_frames.append(self.preprocess(f))\n","                              #batch_frames.append(torch.from_numpy(frame))\n","                              batch_labels.append(label)\n","\n","                              # Check if the batch is complete\n","                              if len(batch_frames) == self.batch_size:\n","                                  # Yield the batch and reset the containers\n","                                  yield torch.stack(batch_frames), torch.tensor(batch_labels)\n","\n","                                  batch_frames = []\n","                                  batch_labels = []\n","\n","              # Yield any remaining data as the last batch\n","              if batch_frames:\n","                  yield torch.stack(batch_frames), torch.tensor(batch_labels)\n","\n","            else: # 'validation', no interleaving between groups\n","              for frames_dataset, labels_dataset, indices in self.group_data:\n","                  for index in indices:\n","                      frame = frames_dataset[index]\n","                      label = labels_dataset[index]\n","                      f = Image.fromarray(frame)\n","                      f = f.convert('RGB') if f.mode != 'RGB' else f\n","                      batch_frames.append(self.preprocess(f))\n","                      batch_labels.append(label)\n","\n","                      if len(batch_frames) == self.batch_size:\n","                          # Yield the batch and reset the containers\n","                          yield torch.stack(batch_frames), torch.tensor(batch_labels)\n","                          batch_frames = []\n","                          batch_labels = []\n","\n","              # Yield any remaining data as the last batch\n","              if batch_frames:\n","                  yield torch.stack(batch_frames), torch.tensor(batch_labels)\n"],"metadata":{"cellView":"form","id":"-k23f7gtvB0M","executionInfo":{"status":"ok","timestamp":1707237871128,"user_tz":-60,"elapsed":14,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["test_generator = FineTuneDataGenerator(dataset_path, 32, preprocess, \"bollinger\", 'train')"],"metadata":{"id":"cDDNqNQZaWXu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title TEST GENERATOR\n","import time\n","# Generate one batch of data\n","\n","start = time.time()\n","frames, labels = next(iter(test_generator))\n","stop = time.time()\n","print(f\"Tempo: {stop-start}\")\n","labels = labels.unsqueeze(1)\n","print(\"Frames shape:\", frames.shape)\n","print(\"Labels shape:\", labels.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8aEbv1BVNTeJ","executionInfo":{"status":"ok","timestamp":1705854011679,"user_tz":-60,"elapsed":18171,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}},"outputId":"0672bf87-adab-49ad-86bc-0b56fddc12a8","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tempo: 17.884037733078003\n","Frames shape: torch.Size([32, 3, 224, 224])\n","Labels shape: torch.Size([32, 1])\n"]}]},{"cell_type":"code","source":["test_generator.shuffle_replenish_data()"],"metadata":{"id":"BI1B0_VUaOlI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Check Frame Generati\n","import cv2\n","\n","unnormalize = transforms.Normalize((-0.48145466/0.26862954, -0.4578275/0.26130258, -0.40821073/0.27577711), (1/0.26862954, 1/0.26130258, 1/0.27577711))\n","img = transforms.ToPILImage()(unnormalize(frames[28])).convert(\"RGB\")\n","img = np.array(img)\n","cv2.imwrite('test.jpg', img)\n","print(labels[31])\n","display(ImagePy('test.jpg'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":258},"id":"AglEFX5iNbL7","executionInfo":{"status":"ok","timestamp":1705854063027,"user_tz":-60,"elapsed":4,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}},"outputId":"5de7b07f-0b81-4e54-e1ca-df16bc55d7a1","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0], dtype=torch.uint8)\n"]},{"output_type":"display_data","data":{"image/jpeg":"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\n","text/plain":["<IPython.core.display.Image object>"]},"metadata":{}}]},{"cell_type":"code","source":["#@title Set Seeds\n","def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    #torch.manual_seed(seed) lo stetto già nel modello\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"],"metadata":{"cellView":"form","id":"Zt4AZjlOut28","executionInfo":{"status":"ok","timestamp":1707237871128,"user_tz":-60,"elapsed":14,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["#@title Classifier Model\n","from torch.nn import functional as F\n","import torch.nn.init as init\n","\n","class MLP(torch.nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.fc1 = torch.nn.Linear(512, 64)\n","        self.bn1 = torch.nn.BatchNorm1d(64)\n","        self.fc2 = torch.nn.Linear(64, 64)\n","        self.bn2 = torch.nn.BatchNorm1d(64)\n","        self.fc3 = torch.nn.Linear(64, 1)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.fc1(x)))\n","        x = F.relu(self.bn2(self.fc2(x)))\n","        x = self.fc3(x)\n","        return x\n","\n","def weights_init(m):\n","    if isinstance(m, torch.nn.Linear):\n","        init.xavier_uniform_(m.weight.data)\n","        print(\"Xavier\")"],"metadata":{"id":"3tDBUJpnjEf-","cellView":"form","executionInfo":{"status":"ok","timestamp":1707237871128,"user_tz":-60,"elapsed":14,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#@title Custom Clip Model\n","class CustomCLIP(torch.nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    torch.manual_seed(0)  # Set the seed\n","    model = clip_model\n","\n","    self.encoder = model.visual.float()\n","\n","    self.classifier = MLP() # Classifier\n","    #self.classifier.apply(weights_init)\n","\n","  def forward(self, x: torch.Tensor) -> torch.Tensor:\n","    x = self.encoder(x)\n","    x = self.classifier(x)\n","    return x"],"metadata":{"id":"n_yi65-jNbKO","cellView":"form","executionInfo":{"status":"ok","timestamp":1707237871128,"user_tz":-60,"elapsed":13,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#@title Training & Test Steps\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score, roc_auc_score\n","\n","def training_step(net, data_loader, optimizer, cost_function, device='cuda'):\n","    samples = 0.0\n","    cumulative_loss = 0.0\n","    cumulative_accuracy = 0.0\n","    true_labels = []\n","    predicted_labels = []\n","\n","    net.train()\n","\n","    # Iterate over the training set\n","    for batch_idx, (frames, labels) in enumerate(tqdm(data_loader, desc=\"Train Progress\", leave=False)):\n","        frames = frames.to(device)\n","        labels = labels.float().unsqueeze(1).to(device)\n","\n","        # Forward pass\n","        outputs = net(frames)\n","\n","        # Loss computation\n","        loss = cost_function(outputs, labels)\n","\n","        optimizer.zero_grad()\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        samples += frames.shape[0]\n","        cumulative_loss += loss.item()\n","\n","        probabilities = torch.sigmoid(outputs)\n","        predictions = (probabilities > 0.5).float()\n","\n","        # Store the true and predicted labels for this batch\n","        true_labels.extend(labels.detach().cpu().numpy())\n","        predicted_labels.extend(predictions.detach().cpu().numpy())\n","\n","        # Compute training accuracy\n","        cumulative_accuracy += predictions.eq(labels).sum().item()\n","\n","    if samples==0: print(\"ZERO SAMPLES GENERATED in train!!!\")\n","\n","    # Convert the lists to numpy arrays\n","    true_labels = np.array(true_labels)\n","    predicted_labels = np.array(predicted_labels)\n","\n","    torch.cuda.empty_cache() #free memory after each epoch\n","\n","    return cumulative_loss / samples, cumulative_accuracy / samples,\n","\n","def test_step(net, data_loader, cost_function, device='cuda'):\n","\n","    cumulative_loss = 0.0\n","    #cumulative_accuracy = 0.0\n","    correct_predictions = 0\n","    total_predictions = 0\n","    true_labels = []\n","    predicted_labels = []\n","\n","    net.eval()\n","\n","    with torch.no_grad():\n","        # Iterate over the test set\n","        for batch_idx, (frames, labels) in enumerate(tqdm(data_loader, desc=\"Eval Progress\", leave=False)):\n","            frames = frames.to(device)\n","            labels = labels.float().unsqueeze(1).to(device)\n","\n","            # Forward pass\n","            outputs = net(frames)\n","\n","            # Loss computation\n","            loss = cost_function(outputs, labels)\n","\n","            total_predictions += frames.shape[0]\n","            cumulative_loss += loss.item()\n","            #_, predicted = outputs.max(1)\n","\n","            probabilities = torch.sigmoid(outputs)\n","            predictions = (probabilities > 0.5).float()\n","\n","            correct_predictions += (predictions == labels).sum().item()\n","\n","            # Store the true and predicted labels for this batch\n","            true_labels.extend(labels.detach().cpu().numpy())\n","            predicted_labels.extend(predictions.detach().cpu().numpy())\n","\n","            # cumulative_accuracy += predictions.eq(labels).sum().item()\n","\n","    if total_predictions==0: print(\"ZERO SAMPLES GENERATED in val!!!\")\n","\n","    test_accuracy = (correct_predictions / total_predictions)\n","\n","    # Convert the lists to numpy arrays\n","    true_labels = np.array(true_labels)\n","    predicted_labels = np.array(predicted_labels)\n","\n","    # Compute F1 score and AUC\n","    f1 = f1_score(true_labels, predicted_labels, average='macro')\n","    auc = roc_auc_score(true_labels, predicted_labels)\n","\n","    return cumulative_loss / total_predictions, test_accuracy, f1, auc"],"metadata":{"cellView":"form","id":"6wCV0EoVNbIm","executionInfo":{"status":"ok","timestamp":1707237871128,"user_tz":-60,"elapsed":13,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#@title TEST 1 TRAINING EPOCH\n","data_loader = FineTuneDataGenerator(dataset_path, 64, preprocess, excluded_person, \"train\")\n","\n","optimizer = torch.optim.Adam(net.parameters(), lr=args['learning_rate'])\n","cost_function = torch.nn.BCEWithLogitsLoss(pos_weight=positive_class_weight_tensor)\n","\n","loss, accuracy = training_step(net, data_loader, optimizer, cost_function, device='cuda')\n","\n","# Print the results\n","print(f\"Average loss: {loss:.4f}, Average accuracy: {accuracy:.2f}%\")"],"metadata":{"id":"Ce_frlhmVWV_","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["args = {\n","      'batch_size':64,\n","      'learning_rate':0.0001,\n","      'weight_decay':0.0001,\n","      'epochs': 15,\n","      'excluded_person':excluded_person,\n","      'class_weight':positive_class_weight_tensor,\n","      'wandb_flag': False\n","    }"],"metadata":{"id":"M7D8PDCheXS_","executionInfo":{"status":"ok","timestamp":1707237871128,"user_tz":-60,"elapsed":13,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["!pip -q install wandb\n","import wandb\n","!wandb login"],"metadata":{"id":"F5Xs3kdtd-oo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707134972961,"user_tz":-60,"elapsed":27447,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}},"outputId":"9f0166c2-bef3-480a-9d23-74c6355b72c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.5/257.5 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}]},{"cell_type":"code","source":["import wandb\n","wandb.init(\n","    project=\"ResNet-Finetuning\",\n","    name=\"no Long - FINAL\",\n","    config={\n","    \"learning_rate\": args['learning_rate'],\n","    \"epochs\": args['epochs'],\n","    \"batch_size\":args['batch_size'],\n","    'weight_decay':args['weight_decay'],\n","    }\n",")"],"metadata":{"id":"hh-nc_TPeEoc","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1707134982877,"user_tz":-60,"elapsed":5523,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}},"outputId":"d718e9da-b053-49ee-afad-8320136baace"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ma-appiani2\u001b[0m (\u001b[33mandrea-unibg\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.2"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240205_120939-40o4e9qp</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/andrea-unibg/ResNet-Finetuning/runs/40o4e9qp' target=\"_blank\">no Long - FINAL</a></strong> to <a href='https://wandb.ai/andrea-unibg/ResNet-Finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/andrea-unibg/ResNet-Finetuning' target=\"_blank\">https://wandb.ai/andrea-unibg/ResNet-Finetuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/andrea-unibg/ResNet-Finetuning/runs/40o4e9qp' target=\"_blank\">https://wandb.ai/andrea-unibg/ResNet-Finetuning/runs/40o4e9qp</a>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/andrea-unibg/ResNet-Finetuning/runs/40o4e9qp?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7eef76a62890>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["#optimizer = torch.optim.SGD(net.parameters(), lr=args['learning_rate'], momentum=0.9, weight_decay=args['weight_decay'])"],"metadata":{"id":"ePPjWTklyXUO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load:\n","checkpoint = torch.load(\"/content/drive/MyDrive/CLIP models/no_long/no_long_9_epochs\")\n","net.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"],"metadata":{"id":"2hOduBqGHbgJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Change weight_decay\n","for param_group in optimizer.param_groups:\n","    param_group['lr'] = 0.00001\n","    param_group['weight_decay'] = 0.0001"],"metadata":{"id":"-thXBgwhTtWu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title MAIN FUNCTION\n","import math\n","\n","def main(\n","      batch_size,\n","      learning_rate,\n","      weight_decay,\n","      epochs,\n","      excluded_person,\n","      class_weight,\n","      wandb_flag\n","    ):\n","  set_seed(42)\n","\n","  train_generator = FineTuneDataGenerator(dataset_path, batch_size, preprocess, excluded_person, mode=\"train\")\n","  val_generator = FineTuneDataGenerator(dataset_path, batch_size, preprocess, excluded_person, mode=\"val\")\n","\n","  #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3)\n","  #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n","\n","  for e in range(epochs):\n","\n","    train_loss, train_accuracy = training_step(net, train_generator, optimizer, cost_function)\n","    val_loss, val_accuracy, val_f1, val_auc = test_step(net, val_generator, cost_function)\n","\n","    train_generator.shuffle_replenish_data()\n","\n","    print('Epoch {:d}:'.format(e+1))\n","    print('\\tTraining loss {:.7f} \\tTraining accuracy {:.4f}'.format(train_loss, train_accuracy))\n","    print('\\tValidation loss {:.7f} \\tValidation accuracy {:.4f}'.format(val_loss, val_accuracy))\n","    print('\\tValid F1 Macro {:.4f}   \\tValidation AUC {:.4f}'.format(val_f1, val_auc))\n","    for param_group in optimizer.param_groups:\n","      print(f\"----------------LR:{param_group['lr']}----------WD:{param_group['weight_decay']}-----------------\")\n","\n","    #scheduler.step(val_f1)\n","    #scheduler.step()\n","\n","    if math.isnan(val_loss):\n","      print(\"NaN values!\")\n","      break\n","\n","    if wandb_flag: wandb.log({\"Training Loss\": train_loss, \"Training Accuracy\": train_accuracy, \"Validation Loss\": val_loss, \"Validation Accuracy\": val_accuracy, \"Val F1 Macro\": val_f1, \"Val AUC\": val_auc})\n","\n","    #------ Save Checkpoint ----------------\n","    torch.save({\n","        'model_state_dict': net.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","    }, f\"/content/drive/MyDrive/CLIP models/no_bollinger/no_bollinger_{e+1}_epochs\")\n","\n","  train_generator.close_file()\n","  val_generator.close_file()\n","  if wandb_flag: wandb.finish()"],"metadata":{"id":"Y4F0i7i9NbG7","cellView":"form","executionInfo":{"status":"ok","timestamp":1707237871129,"user_tz":-60,"elapsed":14,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["#@title Initialize Model\n","net = CustomCLIP().to(device)\n","\n","trainable_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n","print(f'Number of trainable parameters: {trainable_params}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7zY_PSuR9EQU","executionInfo":{"status":"ok","timestamp":1707237871129,"user_tz":-60,"elapsed":14,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}},"outputId":"ca19393a-71a6-4d1c-e8d0-823437182fdf","cellView":"form"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of trainable parameters: 56297249\n"]}]},{"cell_type":"code","source":["optimizer = torch.optim.Adam(net.parameters(), lr=args['learning_rate'], weight_decay = args['weight_decay'])\n","cost_function = torch.nn.BCEWithLogitsLoss(pos_weight=positive_class_weight_tensor)"],"metadata":{"id":"aNkE1m2jyWvr","executionInfo":{"status":"ok","timestamp":1707237871129,"user_tz":-60,"elapsed":12,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["main(**args)"],"metadata":{"id":"VlBl_941NbFQ","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"3880447f-be62-4069-c7b9-8a08ebebc522","executionInfo":{"status":"error","timestamp":1707250063562,"user_tz":-60,"elapsed":9620881,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}}},"execution_count":16,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["--- Training Data ---\n","bell has 37422 indices\n","sick has 38526 indices\n","long has 29391 indices\n","lieberman has 16400 indices\n","--- Validation Data ---\n","bollinger has 15080 indices\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1:\n","\tTraining loss 0.0035565 \tTraining accuracy 0.9322\n","\tValidation loss 0.0113296 \tValidation accuracy 0.4515\n","\tValid F1 Macro 0.4449   \tValidation AUC 0.5038\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2:\n","\tTraining loss 0.0013181 \tTraining accuracy 0.9575\n","\tValidation loss 0.0065457 \tValidation accuracy 0.7174\n","\tValid F1 Macro 0.6382   \tValidation AUC 0.6436\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 3:\n","\tTraining loss 0.0004011 \tTraining accuracy 0.9924\n","\tValidation loss 0.0077038 \tValidation accuracy 0.7092\n","\tValid F1 Macro 0.6958   \tValidation AUC 0.6980\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 4:\n","\tTraining loss 0.0002786 \tTraining accuracy 0.9944\n","\tValidation loss 0.0074192 \tValidation accuracy 0.7514\n","\tValid F1 Macro 0.6988   \tValidation AUC 0.6918\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 5:\n","\tTraining loss 0.0002163 \tTraining accuracy 0.9953\n","\tValidation loss 0.0148895 \tValidation accuracy 0.7108\n","\tValid F1 Macro 0.7108   \tValidation AUC 0.7509\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 6:\n","\tTraining loss 0.0002040 \tTraining accuracy 0.9954\n","\tValidation loss 0.0090379 \tValidation accuracy 0.7000\n","\tValid F1 Macro 0.6840   \tValidation AUC 0.6846\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 7:\n","\tTraining loss 0.0001668 \tTraining accuracy 0.9962\n","\tValidation loss 0.0115587 \tValidation accuracy 0.7288\n","\tValid F1 Macro 0.6550   \tValidation AUC 0.6570\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 8:\n","\tTraining loss 0.0001329 \tTraining accuracy 0.9969\n","\tValidation loss 0.0082752 \tValidation accuracy 0.7256\n","\tValid F1 Macro 0.6873   \tValidation AUC 0.6811\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 9:\n","\tTraining loss 0.0001152 \tTraining accuracy 0.9972\n","\tValidation loss 0.0114893 \tValidation accuracy 0.7471\n","\tValid F1 Macro 0.6868   \tValidation AUC 0.6821\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 10:\n","\tTraining loss 0.0001059 \tTraining accuracy 0.9974\n","\tValidation loss 0.0502062 \tValidation accuracy 0.6156\n","\tValid F1 Macro 0.3811   \tValidation AUC 0.5000\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-f8e639b89338>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-13-7f9a4318bb52>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(batch_size, learning_rate, weight_decay, epochs, excluded_person, class_weight, wandb_flag)\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-cb6b226535e0>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(net, data_loader, optimizer, cost_function, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mcumulative_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import wandb\n","wandb.finish()"],"metadata":{"id":"FOIHV1g8RTRF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"pagIM-eK04aP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6nC_hGiOm5Y5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Tentativi fatti  PROVO LR=0.00001 WD=0.001\n","# riprovo anche a fare le run 4) 5) solo per contrllare che la prima epoca sia uguale\n","\n","1) 10 epochs with LR=0.0001 WD=0.001                        best test F1:76%\n","2) 8 more epochs with same LR and WD                        best test F1:76%    ended because of NaN Losses\n","3) 8 epochs with 4-step-scheduler from LR=0.001 WD:0.001    best test F1:48%    ended because of NaN Losses\n","4) 6 epochs with LR=0.0001 WD=0.0001                        best test F1:45%    ended because of NaN Losses\n","5) 10 epochs with LR=0.0001 WD=0.05                         best test F1:73%\n","6) 6 epochs with LR=0.00001 and WD=0.001                    best test F1:39%    ended because of NaN Losses\n","7) 10 epochs LR=0.0001 WD=0.001 until 7, then LR=0.00001    best test F1:43%"],"metadata":{"id":"_J6wGnjKm5Wj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hRlrcC_cm5UD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2XElT28Lm5P5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"9hvGGTnsm5Nr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qExoMs5Pm5LV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tqU14QDSm5Iu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title 'batch_size':64, 'learning_rate':0.0001, 'weight_decay':0.0001\n","# Epoch: 1\n","# \tTraining loss 0.0035565, \tTraining accuracy 0.932\n","# \tValidation loss 0.0113296, \tValidation accuracy 0.452\n","# \tValid F1 Macro 0.445, \tValidation AUC 0.504\n","\n","# Epoch: 2\n","# \tTraining loss 0.0013181, \tTraining accuracy 0.957\n","# \tValidation loss 0.0065457, \tValidation accuracy 0.717\n","# \tValid F1 Macro 0.638, \tValidation AUC 0.644\n","\n","# Epoch: 3\n","# \tTraining loss 0.0004011, \tTraining accuracy 0.992\n","# \tValidation loss 0.0077038, \tValidation accuracy 0.709\n","# \tValid F1 Macro 0.696, \tValidation AUC 0.698\n","\n","# Epoch: 4\n","# \tTraining loss 0.0002786, \tTraining accuracy 0.994\n","# \tValidation loss 0.0074192, \tValidation accuracy 0.751\n","# \tValid F1 Macro 0.699, \tValidation AUC 0.692\n","\n","# Epoch: 5\n","# \tTraining loss 0.0002163, \tTraining accuracy 0.995\n","# \tValidation loss 0.0148895, \tValidation accuracy 0.711\n","# \tValid F1 Macro 0.711, \tValidation AUC 0.751\n","\n","# Epoch: 6\n","# \tTraining loss 0.0000993, \tTraining accuracy 0.998\n","# \tValidation loss 0.0093492, \tValidation accuracy 0.710\n","# \tValid F1 Macro 0.669, \tValidation AUC 0.664\n","\n","# Epoch: 7\n","# \tTraining loss 0.0000712, \tTraining accuracy 0.999\n","# \tValidation loss 0.0115376, \tValidation accuracy 0.714\n","# \tValid F1 Macro 0.633, \tValidation AUC 0.639"],"metadata":{"id":"iB72_haGQoCW","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title 'batch_size':32,'learning_rate':0.0001,'weight_decay':0.001\n","# Epoch: 1\n","# \tTraining loss 0.0063729, \tTraining accuracy 0.935\n","# \tValidation loss 1.2044284, \tValidation accuracy 0.616\n","# \tValid F1 Macro 0.381, \tValidation AUC 0.500\n","# -----------------------------------------------------\n","# Epoch: 2\n","# \tTraining loss 0.0018923, \tTraining accuracy 0.973\n","# \tValidation loss 0.0172123, \tValidation accuracy 0.653\n","# \tValid F1 Macro 0.478, \tValidation AUC 0.548\n","# -----------------------------------------------------\n","# Epoch: 3\n","# \tTraining loss 0.0009710, \tTraining accuracy 0.989\n","# \tValidation loss 0.0538170, \tValidation accuracy 0.616\n","# \tValid F1 Macro 0.381, \tValidation AUC 0.500\n","# -----------------------------------------------------\n","# Epoch: 4\n","# \tTraining loss 0.0006937, \tTraining accuracy 0.992\n","# \tValidation loss 0.0427640, \tValidation accuracy 0.625\n","# \tValid F1 Macro 0.407, \tValidation AUC 0.512\n","# -----------------------------------------------------\n","# Epoch: 5\n","# \tTraining loss nan, \tTraining accuracy 0.866\n","# \tValidation loss nan, \tValidation accuracy 0.616\n","# \tValid F1 Macro 0.381, \tValidation AUC 0.500"],"metadata":{"id":"3Py6-yToQoAb","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LE2MKdxQQn-a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Q7eiKMJcQn8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Graph\n","import matplotlib.pyplot as plt\n","\n","# Assuming the losses and accuracies are stored in lists\n","epochs = list(range(1, 11))\n","training_loss = [0.00925, 0.00734, 0.00964, 0.00719, 0.00671, 0.00565, 0.00497, 0.00470, 0.00453, 0.00459]\n","validation_loss = [0.00785, 0.00839, 0.04308, 0.00684, 0.00637, 0.00578, 0.00538, 0.00525, 0.00515, 0.00460]\n","\n","plt.figure(figsize=(10,5))\n","\n","# Plotting training loss\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs, training_loss, label='Training Loss')\n","plt.plot(epochs, validation_loss, label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","training_accuracy = [0.62, 0.66, 0.66, 0.63, 0.65, 0.73, 0.80, 0.81, 0.82, 0.82]\n","validation_accuracy = [0.63, 0.61, 0.63, 0.64, 0.66, 0.76, 0.81, 0.80, 0.83, 0.82]\n","\n","# Plotting training accuracy\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs, training_accuracy, label='Training Accuracy')\n","plt.plot(epochs, validation_accuracy, label='Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"PbigxaawuSwg","cellView":"form"},"execution_count":null,"outputs":[]}]}