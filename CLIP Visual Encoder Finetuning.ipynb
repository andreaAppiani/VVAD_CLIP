{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V100","mount_file_id":"1wu3n19owBFAtpLWuzt9rY-QV43aIs5EV","authorship_tag":"ABX9TyMiA0Jg8L9TMpqfIIL6DZx7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Blkz792TNNtF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707237836467,"user_tz":-60,"elapsed":36402,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}},"outputId":"826f32bf-4994-4ca9-fea6-1d6ab7bc9091"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m41.0/53.4 kB\u001b[0m \u001b[31m935.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m937.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]},{"output_type":"stream","name":"stderr","text":["100%|████████████████████████████████████████| 278M/278M [00:02<00:00, 107MiB/s]\n"]}],"source":["#@title CLIP preprocess and Imports\n","!pip -q install ftfy regex tqdm\n","!pip -q install git+https://github.com/openai/CLIP.git\n","import os\n","import numpy as np\n","import h5py\n","import torch\n","import clip\n","import cv2\n","from PIL import Image\n","from IPython.display import Image as ImagePy, display\n","import matplotlib.pyplot as plt\n","import torchvision.transforms as transforms\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","import random\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","clip_model, preprocess = clip.load(\"RN101\")"]},{"cell_type":"code","source":["# Get frame dataset path\n","!cp \"/content/drive/MyDrive/Columbia Dataset/Speaker Frames/database.h5\" \"/content/data.h5\""],"metadata":{"id":"vZmd-e-TOoxJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataset_path = \"/content/data.h5\""],"metadata":{"id":"-XwZpTPX_Sr3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Speaker that will be excluded from finetuning data\n","excluded_person = \"bollinger\""],"metadata":{"id":"5iqKtzOG1FXI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["people_list = [\"bell\",\n","               \"sick\",\n","               \"long\",\n","               #\"bollinger\",\n","               \"lieberman\",\n","               ]"],"metadata":{"id":"QL8W9aYkNTi7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Get Train-Val indices\n","train_val_indices = {}\n","with h5py.File(dataset_path, 'r') as f:\n","    for p in people_list:\n","      person = f[p]\n","      indices = person['frames'].attrs.get(\"data_length\")\n","      train_indices, val_indices = train_test_split(np.arange(indices), test_size=0.2, random_state=42)\n","      train_val_indices[p] = (train_indices, val_indices)"],"metadata":{"id":"-VZkHScrh9e6","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Check Chosen People Data\n","print(\"----------------------- TRAIN DATA ---- VAL DATA --- TOTAL DATA\")\n","with h5py.File(dataset_path, 'r') as f:\n","    tot_train = 0\n","    tot_val = 0\n","    for p in people_list:\n","      person = f[p]\n","      total = person['frames'].attrs.get('data_length')\n","\n","      train_size = len(train_val_indices[p][0])\n","      val_size = len(train_val_indices[p][1])\n","\n","      tot_train += train_size\n","      tot_val += val_size\n","      print(f'Group {p}:      \\t{train_size} \\t\\t{val_size} \\t\\t{total}')\n","\n","    print(f\"TOTAL DATA------------- {tot_train} --------- {tot_val} ---------- {tot_train+tot_val}\")"],"metadata":{"id":"sRNcD6XuNTkl","cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705612607083,"user_tz":-60,"elapsed":4,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}},"outputId":"7506b17a-02e6-4f5c-9fb7-95a8bce8cb4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------- TRAIN DATA ---- VAL DATA --- TOTAL DATA\n","Group bell:      \t29937 \t\t7485 \t\t37422\n","Group sick:      \t30820 \t\t7706 \t\t38526\n","Group long:      \t23512 \t\t5879 \t\t29391\n","Group lieberman:      \t13120 \t\t3280 \t\t16400\n","TOTAL DATA------------- 97389 --------- 24350 ---------- 121739\n"]}]},{"cell_type":"code","source":["#@title Get Class Weights\n","\n","class_counts = {}\n","\n","# Open the HDF5 file\n","with h5py.File(dataset_path, 'r') as f:\n","    # Iterate over each group (person) in the file\n","    for p in [string for string in [\"bell\", \"sick\", \"long\", \"bollinger\", \"lieberman\"] if string != excluded_person]:\n","        person = f[p]\n","        labels = []\n","        indices = f[p]['frames'].attrs.get(\"data_length\")\n","        for index in np.arange(indices):\n","          labels.append(person['labels'][index])\n","        # Count occurrences of each class in the labels\n","        for label in labels:\n","            class_counts[label] = class_counts.get(label, 0) + 1\n","\n","# Calculate total number of training samples\n","total_train_samples = sum(class_counts.values())\n","\n","# Compute class weights as the inverse of class frequencies\n","class_weights = {cls: total_train_samples / count for cls, count in class_counts.items()}\n","\n","# Normalize the weights so that they sum up to 1 (optional)\n","total_weight = sum(class_weights.values())\n","class_weights_normalized = {cls: weight / total_weight for cls, weight in class_weights.items()}\n","print(class_weights_normalized)\n","# Convert class weights to a tensor\n","class_weights_tensor = torch.tensor(list(class_weights_normalized.values()), dtype=torch.float)\n","positive_class_weight_tensor = class_weights_tensor[1].clone().detach().cuda()"],"metadata":{"id":"2QtZOkVte6Gx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707237871128,"user_tz":-60,"elapsed":34663,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}},"outputId":"d995d7de-da05-470a-b310-9d1e471d4471","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 0.41363901461322994, 1: 0.5863609853867701}\n"]}]},{"cell_type":"code","source":["#@title Get TEST Weights\n","class_counts = {}\n","with h5py.File(dataset_path, 'r') as f:\n","  test_labels = f[excluded_person][\"labels\"]\n","  for label in test_labels:\n","    class_counts[label] = class_counts.get(label, 0) + 1\n","\n","# Calculate total number of training samples\n","total_train_samples = sum(class_counts.values())\n","\n","# Compute class weights as the inverse of class frequencies\n","class_weights = {cls: total_train_samples / count for cls, count in class_counts.items()}\n","\n","# Normalize the weights so that they sum up to 1 (optional)\n","total_weight = sum(class_weights.values())\n","class_weights_normalized = {cls: weight / total_weight for cls, weight in class_weights.items()}\n","print(class_weights_normalized)\n","# # Convert class weights to a tensor\n","# class_weights_tensor = torch.tensor(list(class_weights_normalized.values()), dtype=torch.float)\n","# positive_class_weight_tensor = class_weights_tensor[1].clone().detach().cuda()"],"metadata":{"id":"iPNcWPtZuwlC","colab":{"base_uri":"https://localhost:8080/"},"cellView":"form","executionInfo":{"status":"ok","timestamp":1706287408074,"user_tz":-60,"elapsed":322,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}},"outputId":"0037b17b-3ba7-4b7d-c0ad-76b3d97dac1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{0: 0.4305059371916573, 1: 0.5694940628083427}\n"]}]},{"cell_type":"code","source":["#@title Data Loader with better shuffle between people frames\n","class FineTuneDataGenerator:\n","    def __init__(self, data_directory, batch_size, preprocess_f, indices, mode):\n","        self.data_directory = data_directory\n","        self.batch_size = batch_size\n","        self.preprocess = preprocess_f\n","        self.groups = list(indices.keys())\n","        self.mode = mode  # 'train' or 'validation'\n","        self.indices_dict = indices\n","\n","        self.h5_file = h5py.File(self.data_directory, 'r')\n","        group_data = []\n","        for group in self.groups:\n","              frames_dataset = self.h5_file[group]['frames']\n","              labels_dataset = self.h5_file[group]['labels']\n","\n","              if self.mode == 'train':\n","                group_data.append((frames_dataset, labels_dataset, self.indices_dict[group][0]))\n","              else:\n","                group_data.append((frames_dataset, labels_dataset, self.indices_dict[group][1]))\n","\n","        self.group_data = group_data\n","\n","    def close_file(self):\n","      self.h5_file.close()\n","\n","    def shuffle_replenish_data(self):\n","        self.group_data.clear() # resetta la lista di gruppi USATI\n","\n","        for group in self.groups:\n","              frames_dataset = self.h5_file[group]['frames']\n","              labels_dataset = self.h5_file[group]['labels']\n","\n","              if self.mode == 'train':\n","                shuffled_indices = np.random.permutation(self.indices_dict[group][0])\n","                self.group_data.append((frames_dataset, labels_dataset, shuffled_indices))\n","              else:\n","                shuffled_indices = np.random.permutation(self.indices_dict[group][1])\n","                self.group_data.append((frames_dataset, labels_dataset, shuffled_indices))\n","\n","\n","    def __len__(self):\n","        length = 0\n","        for group in self.group_data:\n","          length += len(group[2])\n","\n","        return length // self.batch_size\n","\n","    def __iter__(self):\n","\n","            batch_frames = []\n","            batch_labels = []\n","\n","            # Calculate the number of data points to take from each group per batch\n","            data_per_group = self.batch_size // len(self.groups)\n","\n","            if self.mode == 'train':\n","              # Interleave data from different groups\n","              while any(len(data[2]) for data in self.group_data):\n","                  for _ in range(data_per_group):\n","                      for i, (frames_dataset, labels_dataset, indices) in enumerate(self.group_data):\n","                          if len(indices):\n","                              index = indices[0]\n","                              self.group_data[i] = (frames_dataset, labels_dataset, indices[1:])  # Update the indices in group_data\n","                              frame = frames_dataset[index]\n","                              label = labels_dataset[index]\n","                              f = Image.fromarray(frame)\n","                              f = f.convert('RGB') if f.mode != 'RGB' else f\n","                              batch_frames.append(self.preprocess(f))\n","                              #batch_frames.append(torch.from_numpy(frame))\n","                              batch_labels.append(label)\n","\n","                              # Check if the batch is complete\n","                              if len(batch_frames) == self.batch_size:\n","                                  # Yield the batch and reset the containers\n","                                  yield torch.stack(batch_frames), torch.tensor(batch_labels)\n","\n","                                  batch_frames = []\n","                                  batch_labels = []\n","\n","              # Yield any remaining data as the last batch\n","              if batch_frames:\n","                  yield torch.stack(batch_frames), torch.tensor(batch_labels)\n","\n","            else: # 'validation', no interleaving between groups\n","              for frames_dataset, labels_dataset, indices in self.group_data:\n","                  for index in indices:\n","                      frame = frames_dataset[index]\n","                      label = labels_dataset[index]\n","                      f = Image.fromarray(frame)\n","                      f = f.convert('RGB') if f.mode != 'RGB' else f\n","                      batch_frames.append(self.preprocess(f))\n","                      batch_labels.append(label)\n","\n","                      if len(batch_frames) == self.batch_size:\n","                          # Yield the batch and reset the containers\n","                          yield torch.stack(batch_frames), torch.tensor(batch_labels)\n","                          batch_frames = []\n","                          batch_labels = []\n","\n","              # Yield any remaining data as the last batch\n","              if batch_frames:\n","                  yield torch.stack(batch_frames), torch.tensor(batch_labels)\n"],"metadata":{"id":"f3iRH8PMNTfx","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Data Loader con Validation set = Test set\n","class FineTuneDataGenerator:\n","    def __init__(self, data_directory, batch_size, preprocess_f, excluded_person, mode):\n","        self.data_directory = data_directory\n","        self.batch_size = batch_size\n","        self.preprocess = preprocess_f\n","        self.groups = [\"bell\", \"sick\", \"long\", \"bollinger\", \"lieberman\"]\n","        self.mode = mode  # 'train' or 'validation'\n","        self.excluded_person = excluded_person\n","        self.indices = {}\n","        self.h5_file = h5py.File(self.data_directory, 'r')\n","        group_data = []\n","\n","        # use all people data, except excluded person, for training\n","        if self.mode == 'train':\n","          for group in [string for string in self.groups if string != excluded_person]:\n","              frames_dataset = self.h5_file[group]['frames']\n","              labels_dataset = self.h5_file[group]['labels']\n","              indices = self.h5_file[group]['frames'].attrs.get(\"data_length\")\n","              self.indices[group] = np.arange(indices)\n","\n","              group_data.append((frames_dataset, labels_dataset, np.arange(indices)))\n","\n","          print('--- Training Data ---')\n","          for k in list(self.indices.keys()): print(f'{k} has {len(self.indices[k])} indices')\n","\n","        else: # use excluded person as valdation set\n","          frames_dataset = self.h5_file[excluded_person]['frames']\n","          labels_dataset = self.h5_file[excluded_person]['labels']\n","          indices = self.h5_file[excluded_person]['frames'].attrs.get(\"data_length\")\n","          group_data.append((frames_dataset, labels_dataset, np.arange(indices)))\n","\n","          print(f'--- Validation Data ---\\n{excluded_person} has {indices} indices')\n","\n","        self.group_data = group_data\n","\n","    def close_file(self):\n","      self.h5_file.close()\n","\n","    # for TRAINING only\n","    def shuffle_replenish_data(self):\n","        self.group_data.clear()\n","        for group in [string for string in self.groups if string != self.excluded_person]:\n","              frames_dataset = self.h5_file[group]['frames']\n","              labels_dataset = self.h5_file[group]['labels']\n","\n","              shuffled_indices = np.random.permutation(self.indices[group])\n","              self.group_data.append((frames_dataset, labels_dataset, shuffled_indices))\n","\n","    def __len__(self):\n","        length = 0\n","        for group in self.group_data:\n","          length += len(group[2])\n","\n","        return length // self.batch_size\n","\n","    def __iter__(self):\n","\n","            batch_frames = []\n","            batch_labels = []\n","\n","            # Calculate the number of data points to take from each group per batch\n","            data_per_group = self.batch_size // len(self.groups)\n","\n","            if self.mode == 'train':\n","              # Interleave data from different groups\n","              while any(len(data[2]) for data in self.group_data):\n","                  for _ in range(data_per_group):\n","                      for i, (frames_dataset, labels_dataset, indices) in enumerate(self.group_data):\n","                          if len(indices):\n","                              index = indices[0]\n","                              self.group_data[i] = (frames_dataset, labels_dataset, indices[1:])  # Update the indices in group_data\n","                              frame = frames_dataset[index]\n","                              label = labels_dataset[index]\n","                              f = Image.fromarray(frame)\n","                              f = f.convert('RGB') if f.mode != 'RGB' else f\n","                              batch_frames.append(self.preprocess(f))\n","                              #batch_frames.append(torch.from_numpy(frame))\n","                              batch_labels.append(label)\n","\n","                              # Check if the batch is complete\n","                              if len(batch_frames) == self.batch_size:\n","                                  # Yield the batch and reset the containers\n","                                  yield torch.stack(batch_frames), torch.tensor(batch_labels)\n","\n","                                  batch_frames = []\n","                                  batch_labels = []\n","\n","              # Yield any remaining data as the last batch\n","              if batch_frames:\n","                  yield torch.stack(batch_frames), torch.tensor(batch_labels)\n","\n","            else: # 'validation', no interleaving between groups\n","              for frames_dataset, labels_dataset, indices in self.group_data:\n","                  for index in indices:\n","                      frame = frames_dataset[index]\n","                      label = labels_dataset[index]\n","                      f = Image.fromarray(frame)\n","                      f = f.convert('RGB') if f.mode != 'RGB' else f\n","                      batch_frames.append(self.preprocess(f))\n","                      batch_labels.append(label)\n","\n","                      if len(batch_frames) == self.batch_size:\n","                          # Yield the batch and reset the containers\n","                          yield torch.stack(batch_frames), torch.tensor(batch_labels)\n","                          batch_frames = []\n","                          batch_labels = []\n","\n","              # Yield any remaining data as the last batch\n","              if batch_frames:\n","                  yield torch.stack(batch_frames), torch.tensor(batch_labels)\n"],"metadata":{"cellView":"form","id":"-k23f7gtvB0M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Set Seeds\n","def set_seed(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    #torch.manual_seed(seed) lo stetto già nel modello\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False"],"metadata":{"cellView":"form","id":"Zt4AZjlOut28"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Classifier Model\n","from torch.nn import functional as F\n","import torch.nn.init as init\n","\n","class MLP(torch.nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.fc1 = torch.nn.Linear(512, 64)\n","        self.bn1 = torch.nn.BatchNorm1d(64)\n","        self.fc2 = torch.nn.Linear(64, 64)\n","        self.bn2 = torch.nn.BatchNorm1d(64)\n","        self.fc3 = torch.nn.Linear(64, 1)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.fc1(x)))\n","        x = F.relu(self.bn2(self.fc2(x)))\n","        x = self.fc3(x)\n","        return x\n","\n","def weights_init(m):\n","    if isinstance(m, torch.nn.Linear):\n","        init.xavier_uniform_(m.weight.data)\n","        print(\"Xavier\")"],"metadata":{"id":"3tDBUJpnjEf-","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title CLIP Visual Encoder + Classifier Head\n","class CustomCLIP(torch.nn.Module):\n","  def __init__(self):\n","    super().__init__()\n","    torch.manual_seed(0)  # Set the seed\n","    model = clip_model\n","\n","    self.encoder = model.visual.float()\n","\n","    self.classifier = MLP() # Classifier\n","    #self.classifier.apply(weights_init)\n","\n","  def forward(self, x: torch.Tensor) -> torch.Tensor:\n","    x = self.encoder(x)\n","    x = self.classifier(x)\n","    return x"],"metadata":{"id":"n_yi65-jNbKO","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Training & Test Steps\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score, roc_auc_score\n","\n","def training_step(net, data_loader, optimizer, cost_function, device='cuda'):\n","    samples = 0.0\n","    cumulative_loss = 0.0\n","    cumulative_accuracy = 0.0\n","    true_labels = []\n","    predicted_labels = []\n","\n","    net.train()\n","\n","    # Iterate over the training set\n","    for batch_idx, (frames, labels) in enumerate(tqdm(data_loader, desc=\"Train Progress\", leave=False)):\n","        frames = frames.to(device)\n","        labels = labels.float().unsqueeze(1).to(device)\n","\n","        # Forward pass\n","        outputs = net(frames)\n","\n","        # Loss computation\n","        loss = cost_function(outputs, labels)\n","\n","        optimizer.zero_grad()\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        samples += frames.shape[0]\n","        cumulative_loss += loss.item()\n","\n","        probabilities = torch.sigmoid(outputs)\n","        predictions = (probabilities > 0.5).float()\n","\n","        # Store the true and predicted labels for this batch\n","        true_labels.extend(labels.detach().cpu().numpy())\n","        predicted_labels.extend(predictions.detach().cpu().numpy())\n","\n","        # Compute training accuracy\n","        cumulative_accuracy += predictions.eq(labels).sum().item()\n","\n","    # Convert the lists to numpy arrays\n","    true_labels = np.array(true_labels)\n","    predicted_labels = np.array(predicted_labels)\n","\n","    torch.cuda.empty_cache() #free memory after each epoch\n","\n","    return cumulative_loss / samples, cumulative_accuracy / samples,\n","\n","def test_step(net, data_loader, cost_function, device='cuda'):\n","\n","    cumulative_loss = 0.0\n","    correct_predictions = 0\n","    total_predictions = 0\n","    true_labels = []\n","    predicted_labels = []\n","\n","    net.eval()\n","\n","    with torch.no_grad():\n","        # Iterate over the test set\n","        for batch_idx, (frames, labels) in enumerate(tqdm(data_loader, desc=\"Eval Progress\", leave=False)):\n","            frames = frames.to(device)\n","            labels = labels.float().unsqueeze(1).to(device)\n","\n","            # Forward pass\n","            outputs = net(frames)\n","\n","            # Loss computation\n","            loss = cost_function(outputs, labels)\n","\n","            total_predictions += frames.shape[0]\n","            cumulative_loss += loss.item()\n","            #_, predicted = outputs.max(1)\n","\n","            probabilities = torch.sigmoid(outputs)\n","            predictions = (probabilities > 0.5).float()\n","\n","            correct_predictions += (predictions == labels).sum().item()\n","\n","            # Store the true and predicted labels for this batch\n","            true_labels.extend(labels.detach().cpu().numpy())\n","            predicted_labels.extend(predictions.detach().cpu().numpy())\n","\n","\n","    test_accuracy = (correct_predictions / total_predictions)\n","\n","    # Convert the lists to numpy arrays\n","    true_labels = np.array(true_labels)\n","    predicted_labels = np.array(predicted_labels)\n","\n","    # Compute F1 score and AUC\n","    f1 = f1_score(true_labels, predicted_labels, average='macro')\n","    auc = roc_auc_score(true_labels, predicted_labels)\n","\n","    return cumulative_loss / total_predictions, test_accuracy, f1, auc"],"metadata":{"cellView":"form","id":"6wCV0EoVNbIm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title TEST 1 TRAINING EPOCH\n","data_loader = FineTuneDataGenerator(dataset_path, 64, preprocess, excluded_person, \"train\")\n","\n","optimizer = torch.optim.Adam(net.parameters(), lr=args['learning_rate'])\n","cost_function = torch.nn.BCEWithLogitsLoss(pos_weight=positive_class_weight_tensor)\n","\n","loss, accuracy = training_step(net, data_loader, optimizer, cost_function, device='cuda')\n","\n","# Print the results\n","print(f\"Average loss: {loss:.4f}, Average accuracy: {accuracy:.2f}%\")"],"metadata":{"id":"Ce_frlhmVWV_","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Finetuning Parameters\n","args = {\n","      'batch_size':64,\n","      'learning_rate':0.0001,\n","      'weight_decay':0.0001,\n","      'epochs': 15,\n","      'excluded_person':excluded_person,\n","      'class_weight':positive_class_weight_tensor,\n","      'wandb_flag': False\n","    }"],"metadata":{"id":"M7D8PDCheXS_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip -q install wandb\n","import wandb\n","!wandb login"],"metadata":{"id":"F5Xs3kdtd-oo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707134972961,"user_tz":-60,"elapsed":27447,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}},"outputId":"9f0166c2-bef3-480a-9d23-74c6355b72c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.5/257.5 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}]},{"cell_type":"code","source":["# Weights&Biases setup for logging training results\n","\n","wandb.init(\n","    project=\"ResNet-Finetuning\",\n","    name=\"no Long - FINAL\",\n","    config={\n","    \"learning_rate\": args['learning_rate'],\n","    \"epochs\": args['epochs'],\n","    \"batch_size\":args['batch_size'],\n","    'weight_decay':args['weight_decay'],\n","    }\n",")"],"metadata":{"id":"hh-nc_TPeEoc","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1707134982877,"user_tz":-60,"elapsed":5523,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}},"outputId":"d718e9da-b053-49ee-afad-8320136baace"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ma-appiani2\u001b[0m (\u001b[33mandrea-unibg\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.16.2"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20240205_120939-40o4e9qp</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/andrea-unibg/ResNet-Finetuning/runs/40o4e9qp' target=\"_blank\">no Long - FINAL</a></strong> to <a href='https://wandb.ai/andrea-unibg/ResNet-Finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/andrea-unibg/ResNet-Finetuning' target=\"_blank\">https://wandb.ai/andrea-unibg/ResNet-Finetuning</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/andrea-unibg/ResNet-Finetuning/runs/40o4e9qp' target=\"_blank\">https://wandb.ai/andrea-unibg/ResNet-Finetuning/runs/40o4e9qp</a>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/andrea-unibg/ResNet-Finetuning/runs/40o4e9qp?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7eef76a62890>"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# Load Checkpoint (if necessary):\n","checkpoint = torch.load(\"/content/drive/MyDrive/CLIP models/no_long/no_long_9_epochs\")\n","net.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"],"metadata":{"id":"2hOduBqGHbgJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Change weight_decay of checkpoint (if necessary)\n","for param_group in optimizer.param_groups:\n","    param_group['lr'] = 0.00001\n","    param_group['weight_decay'] = 0.0001"],"metadata":{"id":"-thXBgwhTtWu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title MAIN TRAINING FUNCTION\n","import math\n","\n","def main(\n","      batch_size,\n","      learning_rate,\n","      weight_decay,\n","      epochs,\n","      excluded_person,\n","      class_weight,\n","      wandb_flag\n","    ):\n","  set_seed(42)\n","\n","  train_generator = FineTuneDataGenerator(dataset_path, batch_size, preprocess, excluded_person, mode=\"train\")\n","  val_generator = FineTuneDataGenerator(dataset_path, batch_size, preprocess, excluded_person, mode=\"val\")\n","\n","  #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3)\n","  #scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n","\n","  for e in range(epochs):\n","\n","    train_loss, train_accuracy = training_step(net, train_generator, optimizer, cost_function)\n","    val_loss, val_accuracy, val_f1, val_auc = test_step(net, val_generator, cost_function)\n","\n","    train_generator.shuffle_replenish_data()\n","\n","    print('Epoch {:d}:'.format(e+1))\n","    print('\\tTraining loss {:.7f} \\tTraining accuracy {:.4f}'.format(train_loss, train_accuracy))\n","    print('\\tValidation loss {:.7f} \\tValidation accuracy {:.4f}'.format(val_loss, val_accuracy))\n","    print('\\tValid F1 Macro {:.4f}   \\tValidation AUC {:.4f}'.format(val_f1, val_auc))\n","    for param_group in optimizer.param_groups:\n","      print(f\"----------------LR:{param_group['lr']}----------WD:{param_group['weight_decay']}-----------------\")\n","\n","    #scheduler.step(val_f1)\n","    #scheduler.step()\n","\n","    if math.isnan(val_loss):\n","      print(\"NaN values!\")\n","      break\n","\n","    if wandb_flag: wandb.log({\"Training Loss\": train_loss, \"Training Accuracy\": train_accuracy, \"Validation Loss\": val_loss, \"Validation Accuracy\": val_accuracy, \"Val F1 Macro\": val_f1, \"Val AUC\": val_auc})\n","\n","    #------ Save Checkpoint ----------------\n","    torch.save({\n","        'model_state_dict': net.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","    }, f\"/content/drive/MyDrive/CLIP models/no_bollinger/no_bollinger_{e+1}_epochs\")\n","\n","  train_generator.close_file()\n","  val_generator.close_file()\n","  if wandb_flag: wandb.finish()"],"metadata":{"id":"Y4F0i7i9NbG7","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Initialize Model\n","net = CustomCLIP().to(device)\n","\n","trainable_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n","print(f'Number of trainable parameters: {trainable_params}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7zY_PSuR9EQU","executionInfo":{"status":"ok","timestamp":1707237871129,"user_tz":-60,"elapsed":14,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}},"outputId":"ca19393a-71a6-4d1c-e8d0-823437182fdf","cellView":"form"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of trainable parameters: 56297249\n"]}]},{"cell_type":"code","source":["# Initialize Optimizer & Loss\n","optimizer = torch.optim.Adam(net.parameters(), lr=args['learning_rate'], weight_decay = args['weight_decay'])\n","cost_function = torch.nn.BCEWithLogitsLoss(pos_weight=positive_class_weight_tensor)"],"metadata":{"id":"aNkE1m2jyWvr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["main(**args)"],"metadata":{"id":"VlBl_941NbFQ","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"3880447f-be62-4069-c7b9-8a08ebebc522","executionInfo":{"status":"error","timestamp":1707250063562,"user_tz":-60,"elapsed":9620881,"user":{"displayName":"Andrea Appiani","userId":"00033176299666762154"}}},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["--- Training Data ---\n","bell has 37422 indices\n","sick has 38526 indices\n","long has 29391 indices\n","lieberman has 16400 indices\n","--- Validation Data ---\n","bollinger has 15080 indices\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1:\n","\tTraining loss 0.0035565 \tTraining accuracy 0.9322\n","\tValidation loss 0.0113296 \tValidation accuracy 0.4515\n","\tValid F1 Macro 0.4449   \tValidation AUC 0.5038\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":[""]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 2:\n","\tTraining loss 0.0013181 \tTraining accuracy 0.9575\n","\tValidation loss 0.0065457 \tValidation accuracy 0.7174\n","\tValid F1 Macro 0.6382   \tValidation AUC 0.6436\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 3:\n","\tTraining loss 0.0004011 \tTraining accuracy 0.9924\n","\tValidation loss 0.0077038 \tValidation accuracy 0.7092\n","\tValid F1 Macro 0.6958   \tValidation AUC 0.6980\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 4:\n","\tTraining loss 0.0002786 \tTraining accuracy 0.9944\n","\tValidation loss 0.0074192 \tValidation accuracy 0.7514\n","\tValid F1 Macro 0.6988   \tValidation AUC 0.6918\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 5:\n","\tTraining loss 0.0002163 \tTraining accuracy 0.9953\n","\tValidation loss 0.0148895 \tValidation accuracy 0.7108\n","\tValid F1 Macro 0.7108   \tValidation AUC 0.7509\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 6:\n","\tTraining loss 0.0002040 \tTraining accuracy 0.9954\n","\tValidation loss 0.0090379 \tValidation accuracy 0.7000\n","\tValid F1 Macro 0.6840   \tValidation AUC 0.6846\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 7:\n","\tTraining loss 0.0001668 \tTraining accuracy 0.9962\n","\tValidation loss 0.0115587 \tValidation accuracy 0.7288\n","\tValid F1 Macro 0.6550   \tValidation AUC 0.6570\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 8:\n","\tTraining loss 0.0001329 \tTraining accuracy 0.9969\n","\tValidation loss 0.0082752 \tValidation accuracy 0.7256\n","\tValid F1 Macro 0.6873   \tValidation AUC 0.6811\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 9:\n","\tTraining loss 0.0001152 \tTraining accuracy 0.9972\n","\tValidation loss 0.0114893 \tValidation accuracy 0.7471\n","\tValid F1 Macro 0.6868   \tValidation AUC 0.6821\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 10:\n","\tTraining loss 0.0001059 \tTraining accuracy 0.9974\n","\tValidation loss 0.0502062 \tValidation accuracy 0.6156\n","\tValid F1 Macro 0.3811   \tValidation AUC 0.5000\n","----------------LR:0.0001----------WD:0.0001-----------------\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-f8e639b89338>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-13-7f9a4318bb52>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(batch_size, learning_rate, weight_decay, epochs, excluded_person, class_weight, wandb_flag)\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-cb6b226535e0>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(net, data_loader, optimizer, cost_function, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mcumulative_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import wandb\n","wandb.finish()"],"metadata":{"id":"FOIHV1g8RTRF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"pagIM-eK04aP"},"execution_count":null,"outputs":[]}]}
